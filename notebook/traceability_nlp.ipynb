{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce6d41a4",
   "metadata": {},
   "source": [
    "# Automated Requirements-Test Case Linker\n",
    "This notebook uses Natural Language Processing (NLP) to suggest links between requirements and test cases based on the semantic similarity of their descriptions. It leverages the sentence-transformers library for embedding text and calculating cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7943cc70",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "First, we'll import the necessary libraries and load your requirements and test case data from CSV files. Ensure that requirements.csv and testcases.csv are in the same directory as your notebook, or provide the full file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4bc2462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    reqs = pd.read_csv('requirements.csv')\n",
    "    tests = pd.read_csv('testcases.csv')\n",
    "    print(\"✅ Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Error: Make sure 'requirements.csv' and 'testcases.csv' are in the same directory.\")\n",
    "    # You might want to exit or handle this error more robustly in a real application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dcf625",
   "metadata": {},
   "source": [
    "## 2. Load NLP Model\n",
    "Next, we'll load the pre-trained NLP model from sentence-transformers. The 'all-MiniLM-L6-v2' model is a good choice for general-purpose sentence embeddings due to its balance of performance and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dccaa6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NLP model 'all-MiniLM-L6-v2'...\n",
      "✅ Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load NLP model\n",
    "print(\"Loading NLP model 'all-MiniLM-L6-v2'...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"✅ Model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03caa600",
   "metadata": {},
   "source": [
    "## 3. Encode Descriptions\n",
    "We'll convert the textual descriptions of your requirements and test cases into numerical vectors (embeddings) using the loaded NLP model. These embeddings capture the semantic meaning of the text, allowing for similarity comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa21642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode descriptions\n",
    "print(\"Encoding requirement descriptions...\")\n",
    "req_embeddings = model.encode(reqs['Description'].tolist(), convert_to_tensor=True)\n",
    "print(\"Encoding test case descriptions...\")\n",
    "test_embeddings = model.encode(tests['Description'].tolist(), convert_to_tensor=True)\n",
    "print(\"✅ Descriptions encoded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56872ee6",
   "metadata": {},
   "source": [
    "## 4. Calculate Similarity and Suggest Matches\n",
    "Finally, we'll compute the cosine similarity between each requirement embedding and all test case embeddings. The test case with the highest similarity score will be suggested as a potential match for each requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare using cosine similarity\n",
    "print(\"Calculating cosine similarity between requirements and test cases...\")\n",
    "cosine_scores = util.pytorch_cos_sim(req_embeddings, test_embeddings)\n",
    "print(\"✅ Similarity calculated.\")\n",
    "\n",
    "# Match requirements with the most similar test case\n",
    "print(\"\\n--- Suggested Matches ---\")\n",
    "for i, req_text in enumerate(reqs['Description']):\n",
    "    best_match_idx = cosine_scores[i].argmax()\n",
    "    best_score = cosine_scores[i][best_match_idx].item()\n",
    "    matched_test = tests['Description'][best_match_idx.item()]\n",
    "\n",
    "    print(f\"**Requirement {reqs['Requirement_ID'][i]}:**\")\n",
    "    print(f\"  ↳ *{req_text}*\")\n",
    "    print(f\"**Suggested Match:** {tests['TestCase_ID'][best_match_idx.item()]} - {matched_test}\")\n",
    "    print(f\"**Similarity Score:** {best_score:.4f}\")\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trace-re",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
